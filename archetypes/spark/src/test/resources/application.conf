{
  "app": {
    "name": "SparkServiceTest"
  },
  "engines":{
    "spark": {
      spark.master: "spark://172.26.0.9:7077",
      fs.defaultFS: "hdfs://172.26.0.9:9000",
      spark.sql.warehouse.dir: "hdfs://172.26.0.9:9000/user/hive/warehouse",
      javax.jdo.option.ConnectionDriverName: "com.mysql.jdbc.Driver",
      hive.metastore.uris: "thrift://172.26.0.9:9083",
      javax.jdo.option.ConnectionURL: "jdbc:mysql://172.26.0.9/metastore"
    }
  },
  "ints": {
    "fortyTwo" : 42
  },
  "inputs": [
    {
      schema: "testdatabase",
      table: "tableInput1",
      id: "HiveTableInput1",
      type: "hive"
    },
    {
      schema: "testdatabase",
      table: "tableInput2",
      id: "HiveTableInput2",
      type: "hive"
    },
    {
      path: ["/tmp/hello.txt"],
      formatStr: "text",
      id: "testDelete",
      type: "hdfs"
    },
    {
      path: ["/tmp/hello.txt"],
      formatStr: "text",
      id: "testRow",
      type: "hdfs"
    },
    {
      path: ["/tmp/hello.txt"],
      formatStr: "text",
      id: "testRowAllConf",
      type: "hdfs"
    },
    {
      path: ["/tmp/hello.txt"],
      formatStr: "csv",
      schemaStr: "a String, b String, c String",
      optMap: {
        "delimiter": ";"
      },
      id: "testRowAllConfCsv",
      type: "hdfs"
    },
    {
      path: ["/tmp/hello.txt"],
      formatStr: "text",
      id: "testString",
      type: "hdfs"
    }
  ],
  "outputs":[
    {
      schema: "testdatabase",
      table: "tableOutput",
      writeMode: "Overwrite",
      overridePartitions: false,
      overrideHdfsPartitions: None,
      appId: "",
      id: "HiveTableOutput",
      type: "Hive"
    },
    // Empiezan test HDFS
    {
      path: "/tmp/",
      id: "testDelete",
      type: "hdfs",
      subtype: "delete"
    },
    {
      path: "/tmp/testRow/",
      formatStr: "text",
      id: "testRow",
      type: "hdfs",
      subtype: "Row"
    },
    {
      path: "/tmp/testRowAllConf/",
      formatStr: "text",
      optMap: {
        "compression": "gzip"
      },
      partitionBy: "year",
      id: "testRowAllConf",
      type: "hdfs",
      subtype: "Row"
    },
    {
      path: "/tmp/testRowAllConfCsv/",
      formatStr: "csv",
      optMap: {
        "delimiter": "."
      },
      id: "testRowAllConfCsv",
      type: "hdfs",
      subtype: "Row"
    },
    {
      path: "/tmp/testString.txt",
      id: "testString",
      type: "hdfs",
      subtype: "string"
    }
  ]
}